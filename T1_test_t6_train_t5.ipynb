{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TV6ycAzN1U6h"
   },
   "source": [
    "## LOAD DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1645204956898,
     "user": {
      "displayName": "Đức Duy Dương",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12829553172139770276"
     },
     "user_tz": -420
    },
    "id": "pscRG6416YHa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import math\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 30973,
     "status": "ok",
     "timestamp": 1645204988414,
     "user": {
      "displayName": "Đức Duy Dương",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12829553172139770276"
     },
     "user_tz": -420
    },
    "id": "JD4SiJCm1thD"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('sub_model_15c3d_t5.csv')\n",
    "\n",
    "data2 = pd.read_csv('sub_model_15c3d_t6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1645204988417,
     "user": {
      "displayName": "Đức Duy Dương",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12829553172139770276"
     },
     "user_tz": -420
    },
    "id": "1MgIkmuDpY_2",
    "outputId": "81d73195-afa7-4e10-a951-7b4c15e9a0b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2021050\n",
      "0     763392\n",
      "Name: 15c3d_5, dtype: int64\n",
      "1    2024694\n",
      "0     776481\n",
      "Name: 15c3d_6, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['15c3d_5'].value_counts())\n",
    "print(data2['15c3d_6'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqdsbTi62vRL"
   },
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbehjexYZE37"
   },
   "source": [
    "### DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqck1W-wDdtV"
   },
   "source": [
    "#### DROP OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PORJutPeDkiO"
   },
   "outputs": [],
   "source": [
    "for i in range(2,6):\n",
    "  data = data[data['RC_MONEY_' + str(i)] >= 0]\n",
    "  data2 = data2[data2['RC_MONEY_' + str(i+1)] >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ycG52q5MWmu"
   },
   "source": [
    "#### FILLING NULL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Q0utwb_ZMptB"
   },
   "outputs": [],
   "source": [
    "data['OS'].fillna(\"Unknow\", inplace = True)\n",
    "data2['OS'].fillna(\"Unknow\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-p-0O4YOLVw"
   },
   "source": [
    "#### ENCODING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "REi3oEAoOPxK"
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)\n",
    "data2 = pd.get_dummies(data2)\n",
    "\n",
    "data.drop('OS_Unknow', axis = 1, inplace = True)\n",
    "data2.drop('OS_Unknow', axis =1, inplace = True)\n",
    "data.drop('PRODUCT_CODE', axis= 1, inplace= True)\n",
    "data.drop('PROVINCE', axis= 1, inplace= True)\n",
    "data.drop('TD_5', axis= 1, inplace= True)\n",
    "data.drop('DATA_5', axis= 1, inplace= True)\n",
    "data.drop('ONNET_IN_5', axis= 1, inplace= True)\n",
    "data.drop('ONNET_OUT_5', axis= 1, inplace= True)\n",
    "data.drop('OFFNET_IN_5', axis= 1, inplace= True)\n",
    "data.drop('OFFNET_OUT_5', axis= 1, inplace= True)\n",
    "data.drop('PACK_TIME_5', axis= 1, inplace= True)\n",
    "data.drop('PACK_MONEY_5', axis= 1, inplace= True)\n",
    "data.drop('RC_TIME_5', axis= 1, inplace= True)\n",
    "data.drop('RC_MONEY_5', axis= 1, inplace= True)\n",
    "data.drop('REG_ON_5', axis= 1, inplace= True)\n",
    "\n",
    "data2.drop('PRODUCT_CODE', axis= 1, inplace= True)\n",
    "data2.drop('PROVINCE', axis= 1, inplace= True)\n",
    "data2.drop('TD_6', axis= 1, inplace= True)\n",
    "data2.drop('DATA_6', axis= 1, inplace= True)\n",
    "data2.drop('ONNET_IN_6', axis= 1, inplace= True)\n",
    "data2.drop('ONNET_OUT_6', axis= 1, inplace= True)\n",
    "data2.drop('OFFNET_IN_6', axis= 1, inplace= True)\n",
    "data2.drop('OFFNET_OUT_6', axis= 1, inplace= True)\n",
    "data2.drop('PACK_TIME_6', axis= 1, inplace= True)\n",
    "data2.drop('PACK_MONEY_6', axis= 1, inplace= True)\n",
    "data2.drop('RC_TIME_6', axis= 1, inplace= True)\n",
    "data2.drop('RC_MONEY_6', axis= 1, inplace= True)\n",
    "data2.drop('REG_ON_6', axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tL53BOk9Ri-y"
   },
   "source": [
    "### DATA TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1xwRLTnpRsPZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        AGE      TD_2      TD_3      TD_4    DATA_2    DATA_3    DATA_4  \\\n",
      "0  0.054994  0.000000  0.009464  0.000000  0.000276  0.004625  0.000000   \n",
      "1  0.057613  0.000715  0.001012  0.000798  0.000589  0.000013  0.000026   \n",
      "2  0.092780  0.000149  0.004604  0.000000  0.000000  0.000156  0.000000   \n",
      "3  0.049009  0.000000  0.007098  0.007718  0.000000  0.005340  0.012421   \n",
      "4  0.548822  0.000000  0.004732  0.010291  0.001541  0.003066  0.008059   \n",
      "\n",
      "   ONNET_IN_2  ONNET_IN_3  ONNET_IN_4  ...  RC_MONEY_4  REG_ON_2  REG_ON_3  \\\n",
      "0    0.000637    0.004552    0.000088  ...    0.000000  0.142857  0.935484   \n",
      "1    0.001596    0.000125    0.000115  ...    0.000000  0.285714  0.419355   \n",
      "2    0.000025    0.000007    0.000000  ...    0.000000  0.071429  0.258065   \n",
      "3    0.000000    0.003432    0.004011  ...    0.020000  0.000000  0.645161   \n",
      "4    0.000185    0.000366    0.000322  ...    0.026667  1.000000  1.000000   \n",
      "\n",
      "   REG_ON_4  15c3d_2  15c3d_3  15c3d_4  15c3d_5  OS_FF  OS_SM  \n",
      "0  0.000000        0        1        0        0      0      1  \n",
      "1  0.733333        1        1        1        0      0      1  \n",
      "2  0.066667        0        1        0        1      1      0  \n",
      "3  1.000000        0        1        1        1      0      1  \n",
      "4  1.000000        0        1        1        1      0      0  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nckh1/anaconda3/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- DATA_5\n",
      "- OFFNET_IN_5\n",
      "- OFFNET_OUT_5\n",
      "- ONNET_IN_5\n",
      "- ONNET_OUT_5\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- DATA_2\n",
      "- OFFNET_IN_2\n",
      "- OFFNET_OUT_2\n",
      "- ONNET_IN_2\n",
      "- ONNET_OUT_2\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        AGE      TD_3      TD_4      TD_5    DATA_3    DATA_4    DATA_5  \\\n",
      "0  0.075196  0.005456  0.000473  0.002058  0.004787  0.000702  0.003118   \n",
      "1  0.329966  0.003492  0.004751  0.002573  0.002193  0.002261  0.005235   \n",
      "2  0.046016  0.000000  0.004732  0.012864  0.001291  0.002975  0.007417   \n",
      "3  0.046016  0.000000  0.002366  0.000000  0.000000  0.000637  0.000000   \n",
      "4  0.279835  0.006538  0.003365  0.005377  0.000000  0.000000  0.000000   \n",
      "\n",
      "   ONNET_IN_3  ONNET_IN_4  ONNET_IN_5  ...  RC_MONEY_5  REG_ON_3  REG_ON_4  \\\n",
      "0    0.000515    0.000017    0.000099  ...    0.006667  1.107143  0.967742   \n",
      "1    0.003647    0.001347    0.005638  ...    0.006667  1.071429  0.967742   \n",
      "2    0.000100    0.001519    0.000207  ...    0.033333  0.428571  0.967742   \n",
      "3    0.000031    0.001167    0.000000  ...    0.000000  0.214286  0.225806   \n",
      "4    0.002530    0.002235    0.001284  ...    0.013333  1.071429  0.967742   \n",
      "\n",
      "   REG_ON_5  15c3d_3  15c3d_4  15c3d_5  15c3d_6  OS_FF  OS_SM  \n",
      "0  0.933333        1        1        1        1      0      1  \n",
      "1  1.033333        1        1        1        1      0      1  \n",
      "2  1.000000        0        1        1        0      0      1  \n",
      "3  0.000000        0        1        0        0      0      1  \n",
      "4  1.033333        1        1        1        1      1      0  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data2.drop('ISDN', axis = 1, inplace = True)\n",
    "data.drop('ISDN', axis = 1, inplace = True)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "tmp = scaler.fit_transform(data[data.drop(['15c3d_5','15c3d_2','15c3d_3','15c3d_4','OS_FF','OS_SM'], axis=1).columns])\n",
    "data[data.drop(['15c3d_5','15c3d_2','15c3d_3','15c3d_4','OS_FF','OS_SM'], axis=1).columns] = tmp\n",
    "print(data.head())\n",
    "\n",
    "tmp = scaler.transform(data2[data2.drop(['15c3d_5','15c3d_6','15c3d_3','15c3d_4','OS_FF','OS_SM'], axis=1).columns])\n",
    "data2[data2.drop(['15c3d_6','15c3d_5','15c3d_3','15c3d_4','OS_FF','OS_SM'], axis=1).columns] = tmp\n",
    "\n",
    "print(data2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzJJ4H9jXURJ"
   },
   "source": [
    "## BUILDING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nDMI5lNPnvIv"
   },
   "outputs": [],
   "source": [
    "for col in data2.columns:\n",
    "  if(col[-1] == '3'):\n",
    "    data2 = data2.rename({col : col[:-1] + '2'}, axis=1)\n",
    "  if(col[-1] == '4'):\n",
    "    data2 = data2.rename({col : col[:-1] + '3'}, axis=1) \n",
    "  if(col[-1] == '5'):\n",
    "    data2 = data2.rename({col : col[:-1] + '4'}, axis=1)\n",
    "  if(col[-1] == '6'):\n",
    "    data2 = data2.rename({col : col[:-1] + '5'}, axis=1)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3FO73jPXXYa1"
   },
   "outputs": [],
   "source": [
    "# divide test set and training set\n",
    "X_train = data.drop(\"15c3d_5\", axis= 1)\n",
    "y_train = data['15c3d_5']\n",
    "\n",
    "X_test = data2.drop(\"15c3d_5\", axis=1)\n",
    "y_test = data2['15c3d_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeSoxcuwXf-O"
   },
   "source": [
    "## DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4jzKHL4dYi55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:  0.83971\n",
      "Test set accuracy:  0.82609\n",
      "[[ 428251  348138]\n",
      " [ 138971 1885559]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.55      0.64    776389\n",
      "           1       0.84      0.93      0.89   2024530\n",
      "\n",
      "    accuracy                           0.83   2800919\n",
      "   macro avg       0.80      0.74      0.76   2800919\n",
      "weighted avg       0.82      0.83      0.82   2800919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt=DecisionTreeClassifier(random_state=42, max_depth = 10)\n",
    "dt.fit(X_train,y_train)\n",
    "score = dt.score(X_train, y_train)\n",
    "score2 = dt.score(X_test, y_test)\n",
    "\n",
    "print(\"Training set accuracy: \", '%.5f'%(score))\n",
    "print(\"Test set accuracy: \", '%.5f'%(score2))\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJo14NFRZp4m"
   },
   "source": [
    "### XGBOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "B-T5T52kaLfz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nckh1/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/nckh1/anaconda3/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:11:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nckh1/anaconda3/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:  0.84635\n",
      "Test set accuracy:  0.83541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nckh1/anaconda3/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 459949  316440]\n",
      " [ 144554 1879976]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.59      0.67    776389\n",
      "           1       0.86      0.93      0.89   2024530\n",
      "\n",
      "    accuracy                           0.84   2800919\n",
      "   macro avg       0.81      0.76      0.78   2800919\n",
      "weighted avg       0.83      0.84      0.83   2800919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "score = xgb_model.score(X_train, y_train)\n",
    "score2 = xgb_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Training set accuracy: \", '%.5f'%(score))\n",
    "print(\"Test set accuracy: \", '%.5f'%(score2))\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQcGrkGyarD-"
   },
   "source": [
    "### GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "K7wJhkVIav-0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:  0.84319\n",
      "Test set accuracy:  0.83484\n",
      "[[ 458159  318230]\n",
      " [ 144361 1880169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.59      0.66    776389\n",
      "           1       0.86      0.93      0.89   2024530\n",
      "\n",
      "    accuracy                           0.83   2800919\n",
      "   macro avg       0.81      0.76      0.78   2800919\n",
      "weighted avg       0.83      0.83      0.83   2800919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=125,max_depth=5)\n",
    "gb.fit(X_train, y_train) \n",
    "score = gb.score(X_train, y_train)\n",
    "score2 = gb.score(X_test, y_test)\n",
    "\n",
    "print(\"Training set accuracy: \", '%.5f'%(score))\n",
    "print(\"Test set accuracy: \", '%.5f'%(score2))\n",
    "\n",
    "y_pred = gb.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7JaFnIOb3HQ"
   },
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0MLqnb-fb5y9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:  0.83786\n",
      "Test set accuracy:  0.82932\n",
      "[[ 421138  355251]\n",
      " [ 122798 1901732]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.54      0.64    776389\n",
      "           1       0.84      0.94      0.89   2024530\n",
      "\n",
      "    accuracy                           0.83   2800919\n",
      "   macro avg       0.81      0.74      0.76   2800919\n",
      "weighted avg       0.82      0.83      0.82   2800919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10,\n",
    "                              random_state=42)\n",
    "rf.fit(X_train, y_train) \n",
    "score = rf.score(X_train, y_train)\n",
    "score2 = rf.score(X_test, y_test)\n",
    "\n",
    "print(\"Training set accuracy: \", '%.5f'%(score))\n",
    "print(\"Test set accuracy: \", '%.5f'%(score2))\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'feature': list(X_train.columns),\n",
    "                   'importance': rf.feature_importances_}).\\\n",
    "                    sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>REG_ON_4</td>\n",
       "      <td>0.170098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RC_MONEY_4</td>\n",
       "      <td>0.158706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RC_TIME_4</td>\n",
       "      <td>0.150047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OFFNET_OUT_4</td>\n",
       "      <td>0.082291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TD_4</td>\n",
       "      <td>0.077743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>15c3d_4</td>\n",
       "      <td>0.051858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PACK_MONEY_4</td>\n",
       "      <td>0.046524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DATA_4</td>\n",
       "      <td>0.041377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ONNET_IN_4</td>\n",
       "      <td>0.037697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PACK_TIME_4</td>\n",
       "      <td>0.028699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ONNET_OUT_4</td>\n",
       "      <td>0.021580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>REG_ON_3</td>\n",
       "      <td>0.019637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OFFNET_IN_4</td>\n",
       "      <td>0.017285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.015390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RC_TIME_3</td>\n",
       "      <td>0.013254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TD_3</td>\n",
       "      <td>0.010564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RC_MONEY_3</td>\n",
       "      <td>0.009997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATA_3</td>\n",
       "      <td>0.004601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>15c3d_3</td>\n",
       "      <td>0.004563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15c3d_2</td>\n",
       "      <td>0.003593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TD_2</td>\n",
       "      <td>0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REG_ON_2</td>\n",
       "      <td>0.003378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ONNET_IN_3</td>\n",
       "      <td>0.002847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RC_MONEY_2</td>\n",
       "      <td>0.002609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RC_TIME_2</td>\n",
       "      <td>0.002604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OFFNET_IN_3</td>\n",
       "      <td>0.002479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PACK_MONEY_3</td>\n",
       "      <td>0.002348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OFFNET_OUT_3</td>\n",
       "      <td>0.002222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA_2</td>\n",
       "      <td>0.001932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PACK_TIME_2</td>\n",
       "      <td>0.001562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OFFNET_IN_2</td>\n",
       "      <td>0.001559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ONNET_IN_2</td>\n",
       "      <td>0.001387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PACK_MONEY_2</td>\n",
       "      <td>0.001355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OFFNET_OUT_2</td>\n",
       "      <td>0.001325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PACK_TIME_3</td>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ONNET_OUT_3</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ONNET_OUT_2</td>\n",
       "      <td>0.000928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>OS_SM</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>OS_FF</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  importance\n",
       "33      REG_ON_4    0.170098\n",
       "30    RC_MONEY_4    0.158706\n",
       "27     RC_TIME_4    0.150047\n",
       "18  OFFNET_OUT_4    0.082291\n",
       "3           TD_4    0.077743\n",
       "36       15c3d_4    0.051858\n",
       "24  PACK_MONEY_4    0.046524\n",
       "6         DATA_4    0.041377\n",
       "9     ONNET_IN_4    0.037697\n",
       "21   PACK_TIME_4    0.028699\n",
       "12   ONNET_OUT_4    0.021580\n",
       "32      REG_ON_3    0.019637\n",
       "15   OFFNET_IN_4    0.017285\n",
       "0            AGE    0.015390\n",
       "26     RC_TIME_3    0.013254\n",
       "2           TD_3    0.010564\n",
       "29    RC_MONEY_3    0.009997\n",
       "5         DATA_3    0.004601\n",
       "35       15c3d_3    0.004563\n",
       "34       15c3d_2    0.003593\n",
       "1           TD_2    0.003528\n",
       "31      REG_ON_2    0.003378\n",
       "8     ONNET_IN_3    0.002847\n",
       "28    RC_MONEY_2    0.002609\n",
       "25     RC_TIME_2    0.002604\n",
       "14   OFFNET_IN_3    0.002479\n",
       "23  PACK_MONEY_3    0.002348\n",
       "17  OFFNET_OUT_3    0.002222\n",
       "4         DATA_2    0.001932\n",
       "19   PACK_TIME_2    0.001562\n",
       "13   OFFNET_IN_2    0.001559\n",
       "7     ONNET_IN_2    0.001387\n",
       "22  PACK_MONEY_2    0.001355\n",
       "16  OFFNET_OUT_2    0.001325\n",
       "20   PACK_TIME_3    0.001187\n",
       "11   ONNET_OUT_3    0.000946\n",
       "10   ONNET_OUT_2    0.000928\n",
       "38         OS_SM    0.000214\n",
       "37         OS_FF    0.000085"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qawiSiJddQXm"
   },
   "source": [
    "### DEEP NEURAL DECISION FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "9XAEQ8WAdX1C"
   },
   "outputs": [],
   "source": [
    "data_train = pd.concat([X_train, y_train], axis=1)\n",
    "data_train['15c3d_5'] = data_train['15c3d_5'].astype(str)\n",
    "data_train['15c3d_5'].replace([\"0\", \"1\"], [\"y\", \"n\"], inplace= True)\n",
    "\n",
    "data_test = pd.concat([X_test, y_test], axis=1)\n",
    "data_test['15c3d_5'] = data_test['15c3d_5'].astype(str)\n",
    "data_test['15c3d_5'].replace([\"0\", \"1\"], [\"y\", \"n\"], inplace= True)\n",
    "\n",
    "data_train.to_csv(\"train.csv\", index=False, header=False)\n",
    "data_test.to_csv(\"test.csv\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_wp502_4dYY8"
   },
   "outputs": [],
   "source": [
    "# A list of the numerical feature names.\n",
    "NUMERIC_FEATURE_NAMES = data_train.drop(\"15c3d_5\", axis=1).columns\n",
    "# A dictionary of the categorical features and their vocabulary.\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    \n",
    "}\n",
    "# A list of the columns to ignore from the dataset.\n",
    "#IGNORE_COLUMN_NAMES = [\"fnlwgt\"]\n",
    "# A list of the categorical feature names.\n",
    "CATEGORICAL_FEATURE_NAMES = []\n",
    "# A list of all the input features.\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES\n",
    "# A list of column default values for each feature.\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0.0] if feature_name in NUMERIC_FEATURE_NAMES else [\"NA\"]\n",
    "    for feature_name in data_train.columns\n",
    "]\n",
    "# The name of the target feature.\n",
    "TARGET_FEATURE_NAME = \"15c3d_5\"\n",
    "# A list of the labels of the target features.\n",
    "TARGET_LABELS = [\"y\", \"n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "BvabIk0mdYsE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nckh1/anaconda3/lib/python3.9/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "target_label_lookup = StringLookup(\n",
    "    vocabulary=TARGET_LABELS, mask_token=None, num_oov_indices=0\n",
    ")\n",
    "\n",
    "\n",
    "def get_dataset_from_csv(csv_file_path, shuffle=False, batch_size=128):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=data_train.columns,\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=False,\n",
    "        na_value=\" \",\n",
    "        shuffle=shuffle,\n",
    "    ).map(lambda features, target: (features, target_label_lookup(target)))\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Dq8UvumOdYuu"
   },
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "q428nXfFdYyk"
   },
   "outputs": [],
   "source": [
    "def encode_inputs(inputs):\n",
    "    encoded_features = []\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "            # Create a lookup to convert a string values to an integer indices.\n",
    "            # Since we are not using a mask token, nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and num_oov_indices to 0.\n",
    "            lookup = StringLookup(\n",
    "                vocabulary=vocabulary, mask_token=None, num_oov_indices=0\n",
    "            )\n",
    "            # Convert the string input values into integer indices.\n",
    "            value_index = lookup(inputs[feature_name])\n",
    "            embedding_dims = int(math.sqrt(lookup.vocabulary_size()))\n",
    "            # Create an embedding layer with the specified dimensions.\n",
    "            embedding = layers.Embedding(\n",
    "                input_dim=lookup.vocabulary_size(), output_dim=embedding_dims\n",
    "            )\n",
    "            # Convert the index values to embedding representations.\n",
    "            encoded_feature = embedding(value_index)\n",
    "        else:\n",
    "            # Use the numerical features as-is.\n",
    "            encoded_feature = inputs[feature_name]\n",
    "            if inputs[feature_name].shape[-1] is None:\n",
    "                encoded_feature = tf.expand_dims(encoded_feature, -1)\n",
    "\n",
    "        encoded_features.append(encoded_feature)\n",
    "\n",
    "    encoded_features = layers.concatenate(encoded_features)\n",
    "    return encoded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "2th6VHN1fuHM"
   },
   "outputs": [],
   "source": [
    "class NeuralDecisionTree(keras.Model):\n",
    "    def __init__(self, depth, num_features, used_features_rate, num_classes):\n",
    "        super(NeuralDecisionTree, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.num_leaves = 2 ** depth\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Create a mask for the randomly selected features.\n",
    "        num_used_features = int(num_features * used_features_rate)\n",
    "        one_hot = np.eye(num_features)\n",
    "        sampled_feature_indicies = np.random.choice(\n",
    "            np.arange(num_features), num_used_features, replace=False\n",
    "        )\n",
    "        self.used_features_mask = one_hot[sampled_feature_indicies]\n",
    "\n",
    "        # Initialize the weights of the classes in leaves.\n",
    "        self.pi = tf.Variable(\n",
    "            initial_value=tf.random_normal_initializer()(\n",
    "                shape=[self.num_leaves, self.num_classes]\n",
    "            ),\n",
    "            dtype=\"float32\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        # Initialize the stochastic routing layer.\n",
    "        self.decision_fn = layers.Dense(\n",
    "            units=self.num_leaves, activation=\"sigmoid\", name=\"decision\"\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        batch_size = tf.shape(features)[0]\n",
    "\n",
    "        # Apply the feature mask to the input features.\n",
    "        features = tf.matmul(\n",
    "            features, self.used_features_mask, transpose_b=True\n",
    "        )  # [batch_size, num_used_features]\n",
    "        # Compute the routing probabilities.\n",
    "        decisions = tf.expand_dims(\n",
    "            self.decision_fn(features), axis=2\n",
    "        )  # [batch_size, num_leaves, 1]\n",
    "        # Concatenate the routing probabilities with their complements.\n",
    "        decisions = layers.concatenate(\n",
    "            [decisions, 1 - decisions], axis=2\n",
    "        )  # [batch_size, num_leaves, 2]\n",
    "\n",
    "        mu = tf.ones([batch_size, 1, 1])\n",
    "\n",
    "        begin_idx = 1\n",
    "        end_idx = 2\n",
    "        # Traverse the tree in breadth-first order.\n",
    "        for level in range(self.depth):\n",
    "            mu = tf.reshape(mu, [batch_size, -1, 1])  # [batch_size, 2 ** level, 1]\n",
    "            mu = tf.tile(mu, (1, 1, 2))  # [batch_size, 2 ** level, 2]\n",
    "            level_decisions = decisions[\n",
    "                :, begin_idx:end_idx, :\n",
    "            ]  # [batch_size, 2 ** level, 2]\n",
    "            mu = mu * level_decisions  # [batch_size, 2**level, 2]\n",
    "            begin_idx = end_idx\n",
    "            end_idx = begin_idx + 2 ** (level + 1)\n",
    "\n",
    "        mu = tf.reshape(mu, [batch_size, self.num_leaves])  # [batch_size, num_leaves]\n",
    "        probabilities = keras.activations.softmax(self.pi)  # [num_leaves, num_classes]\n",
    "        outputs = tf.matmul(mu, probabilities)  # [batch_size, num_classes]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "I8p-tFlpfuKN"
   },
   "outputs": [],
   "source": [
    "class NeuralDecisionForest(keras.Model):\n",
    "    def __init__(self, num_trees, depth, num_features, used_features_rate, num_classes):\n",
    "        super(NeuralDecisionForest, self).__init__()\n",
    "        self.ensemble = []\n",
    "        # Initialize the ensemble by adding NeuralDecisionTree instances.\n",
    "        # Each tree will have its own randomly selected input features to use.\n",
    "        for _ in range(num_trees):\n",
    "            self.ensemble.append(\n",
    "                NeuralDecisionTree(depth, num_features, used_features_rate, num_classes)\n",
    "            )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Initialize the outputs: a [batch_size, num_classes] matrix of zeros.\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        outputs = tf.zeros([batch_size, num_classes])\n",
    "\n",
    "        # Aggregate the outputs of trees in the ensemble.\n",
    "        for tree in self.ensemble:\n",
    "            outputs += tree(inputs)\n",
    "        # Divide the outputs by the ensemble size to get the average.\n",
    "        outputs /= len(self.ensemble)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "8WMGC2wRfuOI"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 265\n",
    "num_epochs = 11\n",
    "hidden_units = [64, 64]\n",
    "\n",
    "\n",
    "def run_experiment(model):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    train_dataset = get_dataset_from_csv(\n",
    "        \"train.csv\", shuffle=True, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    model.fit(train_dataset, epochs=num_epochs)\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    print(\"Evaluating the model on the test data...\")\n",
    "    test_dataset = get_dataset_from_csv(\"test.csv\", batch_size=batch_size)\n",
    "\n",
    "    _, accuracy = model.evaluate(test_dataset)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ZHSgxMNEfuRy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/11\n",
      "10507/10507 [==============================] - 637s 60ms/step - loss: 0.3396 - sparse_categorical_accuracy: 0.8480\n",
      "Epoch 2/11\n",
      "10507/10507 [==============================] - 258s 25ms/step - loss: 0.3354 - sparse_categorical_accuracy: 0.8499\n",
      "Epoch 3/11\n",
      "10507/10507 [==============================] - 212s 20ms/step - loss: 0.3346 - sparse_categorical_accuracy: 0.8504\n",
      "Epoch 4/11\n",
      "10507/10507 [==============================] - 212s 20ms/step - loss: 0.3343 - sparse_categorical_accuracy: 0.8504\n",
      "Epoch 5/11\n",
      "10507/10507 [==============================] - 221s 21ms/step - loss: 0.3340 - sparse_categorical_accuracy: 0.8507\n",
      "Epoch 6/11\n",
      "10507/10507 [==============================] - 233s 22ms/step - loss: 0.3336 - sparse_categorical_accuracy: 0.8508\n",
      "Epoch 7/11\n",
      "10507/10507 [==============================] - 260s 25ms/step - loss: 0.3335 - sparse_categorical_accuracy: 0.8510\n",
      "Epoch 8/11\n",
      "10507/10507 [==============================] - 258s 25ms/step - loss: 0.3333 - sparse_categorical_accuracy: 0.8511\n",
      "Epoch 9/11\n",
      "10507/10507 [==============================] - 258s 25ms/step - loss: 0.3330 - sparse_categorical_accuracy: 0.8512\n",
      "Epoch 10/11\n",
      "10507/10507 [==============================] - 255s 24ms/step - loss: 0.3331 - sparse_categorical_accuracy: 0.8511\n",
      "Epoch 11/11\n",
      "10507/10507 [==============================] - 249s 24ms/step - loss: 0.3328 - sparse_categorical_accuracy: 0.8514\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "10570/10570 [==============================] - 275s 26ms/step - loss: 0.3801 - sparse_categorical_accuracy: 0.8285\n",
      "Test accuracy: 82.85%\n"
     ]
    }
   ],
   "source": [
    "depth = 10\n",
    "used_features_rate = 1.0\n",
    "num_classes = len(TARGET_LABELS)\n",
    "\n",
    "\n",
    "def create_tree_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "    features = layers.BatchNormalization()(features)\n",
    "    num_features = features.shape[1]\n",
    "\n",
    "    tree = NeuralDecisionTree(depth, num_features, used_features_rate, num_classes)\n",
    "\n",
    "    outputs = tree(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "tree_model = create_tree_model()\n",
    "run_experiment(tree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.54      0.64    776389\n",
      "           1       0.84      0.94      0.89   2024530\n",
      "\n",
      "    accuracy                           0.83   2800919\n",
      "   macro avg       0.81      0.74      0.76   2800919\n",
      "weighted avg       0.82      0.83      0.82   2800919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = get_dataset_from_csv(\"test.csv\", batch_size=batch_size)\n",
    "aa = tree_model.predict(test_dataset)\n",
    "y_pred = []\n",
    "i = 0\n",
    "for a in aa:\n",
    "  if a[0] > a[1]:\n",
    "    y_pred.append(0)\n",
    "  else:\n",
    "    y_pred.append(1)\n",
    "  i = i + 1\n",
    "y_pred = np.array(y_pred)\n",
    "print(y_pred)\n",
    "y_test = data_test['15c3d_5']\n",
    "y_test.replace([\"y\", \"n\"], [\"0\", \"1\"], inplace= True)\n",
    "y_test = y_test.astype(np.int64)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "XxNZ1mwdgCms"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/11\n",
      "10507/10507 [==============================] - 514s 47ms/step - loss: 0.3416 - sparse_categorical_accuracy: 0.8462\n",
      "Epoch 2/11\n",
      "10507/10507 [==============================] - 170s 16ms/step - loss: 0.3401 - sparse_categorical_accuracy: 0.8472\n",
      "Epoch 3/11\n",
      "10507/10507 [==============================] - 174s 17ms/step - loss: 0.3391 - sparse_categorical_accuracy: 0.8477\n",
      "Epoch 4/11\n",
      "10507/10507 [==============================] - 172s 16ms/step - loss: 0.3385 - sparse_categorical_accuracy: 0.8481\n",
      "Epoch 5/11\n",
      "10507/10507 [==============================] - 171s 16ms/step - loss: 0.3390 - sparse_categorical_accuracy: 0.8480\n",
      "Epoch 6/11\n",
      "10507/10507 [==============================] - 172s 16ms/step - loss: 0.3404 - sparse_categorical_accuracy: 0.8471\n",
      "Epoch 7/11\n",
      "10507/10507 [==============================] - 177s 17ms/step - loss: 0.3411 - sparse_categorical_accuracy: 0.8470\n",
      "Epoch 8/11\n",
      "10507/10507 [==============================] - 152s 14ms/step - loss: 0.3409 - sparse_categorical_accuracy: 0.8471\n",
      "Epoch 9/11\n",
      "10507/10507 [==============================] - 136s 13ms/step - loss: 0.3414 - sparse_categorical_accuracy: 0.8467\n",
      "Epoch 10/11\n",
      "10507/10507 [==============================] - 147s 14ms/step - loss: 0.3403 - sparse_categorical_accuracy: 0.8473\n",
      "Epoch 11/11\n",
      "10507/10507 [==============================] - 714s 68ms/step - loss: 0.3402 - sparse_categorical_accuracy: 0.8473\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "10570/10570 [==============================] - 1438s 134ms/step - loss: 0.3903 - sparse_categorical_accuracy: 0.8236\n",
      "Test accuracy: 82.36%\n"
     ]
    }
   ],
   "source": [
    "num_trees = 25\n",
    "depth = 5\n",
    "used_features_rate = 0.5\n",
    "\n",
    "\n",
    "def create_forest_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "    features = layers.BatchNormalization()(features)\n",
    "    num_features = features.shape[1]\n",
    "\n",
    "    forest_model = NeuralDecisionForest(\n",
    "        num_trees, depth, num_features, used_features_rate, num_classes\n",
    "    )\n",
    "\n",
    "    outputs = forest_model(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "forest_model = create_forest_model()\n",
    "\n",
    "run_experiment(forest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "5gxrEbQMyEk_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.53      0.62    776389\n",
      "           1       0.84      0.94      0.88   2024530\n",
      "\n",
      "    accuracy                           0.82   2800919\n",
      "   macro avg       0.80      0.73      0.75   2800919\n",
      "weighted avg       0.82      0.82      0.81   2800919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aa = forest_model.predict(test_dataset)\n",
    "y_pred = []\n",
    "i = 0\n",
    "for a in aa:\n",
    "  if a[0] > a[1]:\n",
    "    y_pred.append(0)\n",
    "  else:\n",
    "    y_pred.append(1)\n",
    "  i = i + 1\n",
    "y_pred = np.array(y_pred)\n",
    "print(y_pred)\n",
    "y_test = data_test['15c3d_5']\n",
    "y_test.replace([\"y\", \"n\"], [\"0\", \"1\"], inplace= True)\n",
    "y_test = y_test.astype(np.int64)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN0GaY9rtr3t7BswQciIYMn",
   "collapsed_sections": [],
   "mount_file_id": "1D0Wm-ysEpK_wDgISV6NE9kOANH8u-Rs3",
   "name": "T1_test_t6_train_t5.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/Duyih25/btvn_lab/blob/main/All_models.ipynb",
     "timestamp": 1645037524944
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
